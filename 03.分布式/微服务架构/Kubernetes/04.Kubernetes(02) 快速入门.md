# 应用部署方式演变

在部署应用程序的方式上，主要经历了三个时代：

![img](04.Kubernetes(02) 快速入门.assets/2195406-20210704100824640-706104489.png)

 ![img](04.Kubernetes(02) 快速入门.assets/2195406-20210704101008611-744581917.png)

 容器化部署方式给带来很多的便利，但是也会出现一些问题，比如说：

1、一个容器故障停机了，怎么样让另外一个容器立刻启动去替补停机的容器
2、当并发访问量变大的时候，怎么样做到横向扩展容器数量

这些容器管理的问题统称为容器编排问题，为了解决这些容器编排问题，就产生了一些容器编排的软件：

```
Swarm：Docker自己的容器编排工具
Mesos：Apache的一个资源统一管控的工具，需要和Marathon结合使用
Kubernetes：Google开源的的容器编排工具
```

 

# kubernetes介绍

kubernetes是一个全新的基于容器技术的分布式架构领先方案，是谷歌严格保密十几年的秘密武器----Borg系统的一个开源版本，于2014年9月发布第一个版本，2015年7月发布第一个正式版本。

kubernetes的本质是一组服务器集群，它可以在集群的每个节点上运行特定的程序，来对节点中的容器进行管理。目的是实现资源管理的自动化，主要提供了如下的主要功能：

- **自我修复**：一旦某一个容器崩溃，能够在1秒中左右迅速启动新的容器
- **弹性伸缩**：可以根据需要，自动对集群中正在运行的容器数量进行调整
- **服务发现**：服务可以通过自动发现的形式找到它所依赖的服务
- **负载均衡**：如果一个服务起动了多个容器，能够自动实现请求的负载均衡
- **版本回退**：如果发现新发布的程序版本有问题，可以立即回退到原来的版本
- **存储编排**：可以根据容器自身的需求自动创建存储卷



# kubernetes概念

**Master**：集群控制节点，每个集群需要至少一个master节点负责集群的管控

**Node**：工作负载节点，由master分配容器到这些node工作节点上，然后node节点上的docker负责容器的运行

**Pod**：kubernetes的最小控制单元，容器都是运行在pod中的，一个pod中可以有1个或者多个容器

**Controller**：控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等

**Service**：pod对外服务的统一入口，下面可以维护者同一类的多个pod

**Label**：标签，用于对pod进行分类，同一类pod会拥有相同的标签

**NameSpace**：命名空间，用来隔离pod的运行环境



# kubernetes组件

> 一个kubernetes集群主要是由**控制节点**(master)、**工作节点**(node)构成，每个节点上都会安装不同的组件。

**master：集群的控制平面，负责集群的决策 ( 管理 )**

```perl
ApiServer : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制
Scheduler : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上
ControllerManager : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等
Etcd ：负责存储集群中各种资源对象的信息，k/v方式存储，所有的 k8s 集群数据存放在此
Kuberctl ：命令行配置工具
```

**node：集群的数据平面，负责为容器提供运行环境 ( 干活 )**

```perl
Kubelet : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器，会按固定频率检查节点健康状态并上报给 APIServer，该状态会记录在 Node 对象的 status 中。
KubeProxy : 负责提供集群内部的服务发现和负载均衡
Docker : 负责节点上容器的各种操作
```

![img](04.Kubernetes(02) 快速入门.assets/2195406-20210704101731540-438323924.png)

```perl
下面，以部署一个nginx服务来说明kubernetes系统各个组件调用关系：

1. 首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中
2. 一个nginx服务的安装请求会首先被发送到master节点的apiServer组件
3. apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上
　　在此时，它会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer
4. apiServer调用controller-manager去调度Node节点安装nginx服务
5. kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod
　　pod是kubernetes的最小操作单元，容器必须跑在pod中至此，
6. 一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理

这样，外界用户就可以访问集群中的nginx服务了
```

 

# 资源管理介绍

在kubernetes中，所有的内容都抽象为资源，用户需要通过操作资源来管理kubernetes

> kubernetes的本质上就是一个集群系统，用户可以在集群中部署各种服务，所谓的部署服务，其实 就是在kubernetes集群中运行一个个的容器，并将指定的程序跑在容器中。
>
> kubernetes的最小管理单元是pod而不是容器，所以只能将容器放在 **Pod** 中，而kubernetes一般也 不会直接管理Pod，而是通过 **Pod控制器** 来管理Pod的。
>
> Pod可以提供服务之后，就要考虑如何访问Pod中服务，kubernetes提供了 **Service** 资源实现这个 功能。
>
> 当然，如果Pod中程序的数据需要持久化，kubernetes还提供了各种 **存储** 系统。



> 学习kubernetes的核心，就是学习如何对集群上的`Pod、Pod控制器、Service、存储`等各种资源进行操作

![img](04.Kubernetes(02) 快速入门.assets/2195406-20210525110457185-1898835847.png)

> kubernetes在集群启动之后，会默认创建几个namespace:default、kube-node-lease、kube-public、kube-system     

默认情况下，kubernetes集群中的所有的Pod都是可以相互访问的。但是在实际中，可能不想让两个Pod之间进行互相的访问，那此时就可以将两个Pod划分到不同的namespace下。kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的"组"，以方便不同的组的资源进行隔离使用和管理。



# YAML语言介绍

YAML是一个类似 XML、JSON 的标记性语言。它强调以数据为中心，并不是以标识语言为重点。因而YAML本身的定义比较简单，号称"一种人性化的数据格式语言"。

```xml
<heima>
  <age>15</age>
  <address>Beijing</address>
</heima>
```

等于：

```yaml
heima:
  age: 15
  address: Beijing
```

YAML的语法比较简单，主要有下面几个：

　　大小写敏感

　　使用缩进表示层级关系

　　缩进不允许使用tab，只允许空格( 低版本限制 )

　　缩进的空格数不重要，只要相同层级的元素左对齐即可

　　'#'表示注释

YAML支持以下几种数据类型：

　　纯量：单个的、不可再分的值

　　对象：键值对的集合，又称为映射（mapping）/ 哈希（hash） / 字典（dictionary）

　　数组：一组按次序排列的值，又称为序列（sequence） / 列表（list）

```perl
# 纯量, 就是指的一个简单的值，字符串、布尔值、整数、浮点数、Null、时间、日期
# 1 布尔类型
c1: true (或者True)
# 2 整型
c2: 234
# 3 浮点型
c3: 3.14
# 4 null类型
c4: ~  # 使用~表示null
# 5 日期类型
c5: 2018-02-17   # 日期必须使用ISO 8601格式，即yyyy-MM-dd
# 6 时间类型
c6: 2018-02-17T15:02:31+08:00  # 时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表
时区
# 7 字符串类型
c7: heima   # 简单写法，直接写值 , 如果字符串中间有特殊字符，必须使用双引号或者单引号包裹
c8: line1
 line2   # 字符串过多的情况可以拆成多行，每一行会被转化成一个空格
```



```perl
# 对象
# 形式一(推荐):
heima:
age: 15
address: Beijing
# 形式二(了解):
heima: {age: 15,address: Beijing}
```



```perl
# 数组
# 形式一(推荐):
address:
- 顺义
- 昌平
# 形式二(了解):
address: [顺义,昌平]
```



```perl
小提示：
1 书写yaml切记 : 后面要加一个空格
2 如果需要将多段yaml配置放在一个文件中，中间要使用 --- 分隔
3 下面是一个yaml转json的网站，可以通过它验证yaml是否书写正确
　　https://www.json2yaml.com/convert-yaml-to-json
```

 

# 资源管理方式

**命令式对象管理**：直接使用命令去操作kubernetes资源

```shell
kubectl run nginx-pod --image=nginx:1.17.1 --port=80
```

**命令式对象配置**：通过命令配置和配置文件去操作kubernetes资源

```shell
kubectl create/patch -f nginx-pod.yaml
```

**声明式对象配置**：通过apply命令和配置文件去操作kubernetes资源

```shell
kubectl apply -f nginx-pod.yaml 
```

 

| 类型           | 操作对象 | 使用环境 | 优点           | 缺点                             |
| -------------- | -------- | -------- | -------------- | -------------------------------- |
| 命令式对象管理 | 对象     | 测试     | 简单           | 只能操作活动对象，无法审计、跟踪 |
| 命令式对象配置 | 文件     | 开发     | 可以审计、跟踪 | 项目大时，配置文件多，操作麻烦   |
| 声明式对象配置 | 目录     | 开发     | 支持目录操作   | 意外情况下难以调试               |



#  命令式对象管理

## **kubectl命令**

kubectl是kubernetes集群的命令行工具，通过它能够对集群本身进行管理，并能够在集群上进行容器化

应用的安装部署。kubectl命令的语法如下：

```perl
kubectl [command] [type] [name] [flags]
```

**comand**：指定要对资源执行的操作，例如create、get、delete

**type**：指定资源类型，比如deployment、pod、service

**name**：指定资源的名称，名称大小写敏感

**flags**：指定额外的可选参数

```shell
# 查看所有
pod kubectl get pod

# 查看某个
pod kubectl get pod pod_name

# 查看某个pod,以yaml格式展示结果
kubectl get pod pod_name -o yaml
```

 

##  资源类型

 kubernetes中所有的内容都抽象为资源，可以通过下面的命令进行查看:

```perl
kubectl api-resources
```

经常使用的资源下面我做了划分：

![img](04.Kubernetes(02) 快速入门.assets/2195406-20210526085437990-1350683146.png)

 

##  操作

 kubernetes允许对资源进行多种操作，可以通过--help查看详细的操作命令

```perl
kubectl --help
```

经常使用的操作有下面这些：

 ![img](04.Kubernetes(02) 快速入门.assets/2195406-20210526085558019-1443578869.png)

 

 **下面以一个namespace / pod的创建和删除简单演示下命令的使用：**

```shell
# 创建一个namespace
[root@master ~]# kubectl create namespace dev
namespace/dev created
# 获取namespace
[root@master ~]# kubectl get ns
NAME             STATUS  AGE
default          Active  21h
dev              Active  21s
kube-node-lease  Active  21h
kube-public      Active  21h
kube-system      Active  21h
# 在此namespace下创建并运行一个nginx的Pod
[root@master ~]# kubectl run pod --image=nginx -n dev
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a
future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.deployment.apps/pod created

# 查看新创建的pod
[root@master ~]# kubectl get pod -n dev
NAME          READY  STATUS   RESTARTS  AGE
pod-864f9875b9-pcw7x  1/1   Running  0      21s
# 删除指定的pod
[root@master ~]# kubectl delete pod pod-864f9875b9-pcw7x
pod "pod-864f9875b9-pcw7x" deleted
# 删除指定的namespace
[root@master ~]# kubectl delete ns dev
namespace "dev" deleted
```

 

##  命令式对象配置

 命令式对象配置就是使用命令配合配置文件一起来操作kubernetes资源。

 1） 创建一个nginxpod.yaml，内容如下：

```yaml
apiVersion: v1   #指定版本
kind: Namespace  #指定类型
  metadata:      #数据描述
    name: dev    #名字
---
apiVersion: v1   #指定版本
kind: Pod        #指定类型
metadata:        #数据描述
  name: nginxpod #名字
  namespace: dev #命名空间
spec:            #详细说明描述
  containers:    #容器
  - name: nginx-containers  #nginx容器
    image: nginx:1.17.1     #指定镜像版本
```



2）执行create命令，创建资源：

```shell
[root@master ~]# kubectl create -f nginxpod.yaml
namespace/dev created
pod/nginxpod created
```

此时发现创建了两个资源对象，分别是namespace和pod



3）执行get命令，查看资源：

```shell
[root@master ~]# kubectl get -f nginxpod.yaml
NAME       STATUS  AGE
namespace/dev  Active  18s
NAME       READY  STATUS   RESTARTS  AGE
pod/nginxpod   1/1   Running  0      17s
```

这样就显示了两个资源对象的信息



4）执行delete命令，删除资源：

```shell
[root@master ~]# kubectl delete -f nginxpod.yaml
namespace "dev" deleted
pod "nginxpod" deleted
```

此时发现两个资源对象被删除了

```perl
总结:
　　命令式对象配置的方式操作资源，可以简单的认为：命令 + yaml配置文件（里面是命令需要的各种参数）
```

 

## 声明式对象配置

声明式对象配置跟命令式对象配置很相似，但是它只有一个命令apply。

```shell
# 首先执行一次kubectl apply -f yaml文件，发现创建了资源
[root@master ~]# kubectl apply -f nginxpod.yaml
namespace/dev created
pod/nginxpod created
# 再次执行一次kubectl apply -f yaml文件，发现说资源没有变动
[root@master ~]# kubectl apply -f nginxpod.yaml
namespace/dev unchanged
pod/nginxpod unchanged
```



```perl
总结:
 　其实声明式对象配置就是使用apply描述一个资源最终的状态（在yaml中定义状态）
使用apply操作资源：
   如果资源不存在，就创建，相当于 kubectl create
　　如果资源已存在，就更新，相当于 kubectl patch
```



**扩展：kubectl可以在node节点上运行吗 ?**

kubectl的运行是需要进行配置的，它的配置文件是$HOME/.kube，如果想要在node节点运行此命令，需
要将master上的.kube文件复制到node节点上，即在master节点上执行下面操作

```perl
scp  -r  HOME/.kube  node1: HOME/
```

 

**使用推荐: 三种方式应该怎么用 ?**

　　创建/更新资源 使用声明式对象配置 kubectl apply -f XXX.yaml

　　删除资源 使用命令式对象配置 kubectl delete -f XXX.yaml

　　查询资源 使用命令式对象管理 kubectl get(describe) 资源名称



## 扩展

**kubectl可以在node节点上运行吗 ?**

kubectl的运行是需要进行配置的，它的配置文件是$HOME/.kube，如果想要在node节点运行此命令，需
要将master上的.kube文件复制到node节点上，即在master节点上执行下面操作：

```
scp  -r  HOME/.kube  node1: HOME/
```



# 概念

## 1. Namespace

1. Namespace是kubernetes系统中的一种非常重要资源，它的主要作用是用来实现**多套环境的资源隔离**或者**多租户的资源隔离**。

2. 默认情况下，kubernetes集群中的所有的Pod都是可以相互访问的。但是在实际中，可能不想让两个Pod之间进行互相的访问，那此时就可以将两个Pod划分到不同的namespace下。kubernetes通过将集群内部的资源分配到不同的Namespace中，可以形成逻辑上的"组"，以方便不同的组的资源进行隔离使用和管理。

3. 可以通过kubernetes的授权机制，将不同的namespace交给不同租户进行管理，这样就实现了多租户的资源隔离。此时还能结合kubernetes的资源配额机制，限定不同租户能占用的资源，例如CPU使用量、内存使用量等等，来实现租户可用资源的管理。

 如图：

![image-20220522103835376](04.Kubernetes(02) 快速入门.assets/image-20220522103835376.png)

 ![img](04.Kubernetes(02) 快速入门.assets/2195406-20210531072439942-994249682.png)

 应用示例

- kubernetes在集群启动之后，会默认创建几个namespace

  ```perl
  [root@master ~]# kubectl  get namespace
  NAME              STATUS   AGE
  default           Active   45h     #  所有未指定Namespace的对象都会被分配在default命名空间
  kube-node-lease   Active   45h     #  集群节点之间的心跳维护，v1.13开始引入
  kube-public       Active   45h     #  此命名空间下的资源可以被所有人访问（包括未认证用户）
  kube-system       Active   45h     #  所有由Kubernetes系统创建的资源都处于这个命名空间
  ```

下面来看namespace资源的具体操作：

* NameSpace 查用指令：

  ```perl
  # 查看所有的ns 命令：kubectl get ns
  # 查看指定的ns  命令：kubectl get ns ns 名称
  # 指定输出格式 命令：kubectl get ns ns 名称 -o 格式参数
  	# kubernetes支持的格式有很多，比较常见的是wide、json、yaml [root@master ~]# kubectl get ns default -o yaml
  
  # 查看ns详情 命令：kubectl describe ns ns 名称
  # 创建namespace：kubectl create ns dev
  # 删除namespace：kubectl delete ns dev
  ```

- **查看**

  ```perl
  # 1 查看所有的ns  命令：kubectl get ns
  [root@master ~]# kubectl get ns
  NAME              STATUS   AGE
  default           Active   45h
  kube-node-lease   Active   45h
  kube-public       Active   45h     
  kube-system       Active   45h     
  
  # 2 查看指定的ns   命令：kubectl get ns ns名称
  [root@master ~]# kubectl get ns default
  NAME      STATUS   AGE
  default   Active   45h
  
  # 3 指定输出格式  命令：kubectl get ns ns名称  -o 格式参数
  # kubernetes支持的格式有很多，比较常见的是wide、json、yaml
  [root@master ~]# kubectl get ns default -o yaml
  apiVersion: v1
  kind: Namespace
  metadata:
    creationTimestamp: "2020-04-05T04:44:16Z"
    name: default
    resourceVersion: "151"
    selfLink: /api/v1/namespaces/default
    uid: 7405f73a-e486-43d4-9db6-145f1409f090
  spec:
    finalizers:
    - kubernetes
  status:
    phase: Active
    
  # 4 查看ns详情  命令：kubectl describe ns ns名称
  [root@master ~]# kubectl describe ns default
  Name:         default
  Labels:       <none>
  Annotations:  <none>
  Status:       Active  # Active 命名空间正在使用中  Terminating 正在删除命名空间
  
  # ResourceQuota 针对namespace做的资源限制
  # LimitRange针对namespace中的每个组件做的资源限制
  No resource quota.
  No LimitRange resource.
  ```

- **创建**

  ```perl
  # 创建namespace
  [root@master ~]# kubectl create ns dev
  namespace/dev created
  ```

- **删除**

  ```perl
  # 删除namespace
  [root@master ~]# kubectl delete ns dev
  namespace "dev" deleted
  ```

- **配置方式**
  首先准备一个yaml文件：ns-dev.yaml

  ```perl
  apiVersion: v1
  kind: Namespace
  metadata:
    name: dev
  ```

然后就可以执行对应的创建和删除命令了：

- 创建：kubectl  create  -f  ns-dev.yaml

- 删除：kubectl  delete  -f  ns-dev.yaml




## 2. Pod

Pod是kubernetes集群进行管理的最小单元，程序要运行必须部署在容器中，而容器必须存在于Pod中。

Pod可以认为是容器的封装，一个Pod中可以存在一个或者多个容器。

同一个Pod中的容器共享 IP 地址，进程间的通讯（IPC），主机名以及其他资源。

同一 Node 中的 Pod 的默认路由都是 docker0 的地址，由于他们关联在同一个 docker0 网桥上，地址段相同，所以能直接通信。

不同 Node 中的 Pod 间通信要满足 2 哥条件： Pod 的 IP 不能冲突；将 Pod 的 IP 和所在的 Node 的 IP 关联起来，通过这个关联让 Pod 可以互相访问。 



 就例如下图中：一个Pod组件中有许多的容器在运行。但是最底层的Pause容器就只有一个，它是**Pod的底层运行**，必不可少。我们可以在Pod中运行多个容器，放行多个端口

<img src="04.Kubernetes(02) 快速入门.assets/2195406-20210531073707125-1282238404.png" alt="img" style="zoom:80%;" />

 



### 2.1 pod的生命周期

> - pod创建过程
> - 运行初始化容器（init container）过程
> - 运行主容器（main container）
>   - 容器启动后钩子（post start）、容器终止前钩子（pre stop）
>   - 容器的存活性探测（liveness probe）、就绪性探测（readiness probe）
> - pod终止过程

<img src="04.Kubernetes(02) 快速入门.assets/watermark_03.png" alt="img" style="zoom:80%;" />

在整个生命周期中，Pod会出现5种**状态**（**相位**），分别如下：

- 挂起（Pending）：apiserver已经创建了pod资源对象，但它尚未被调度完成或者仍处于下载镜像的过程中
- 运行中（Running）：pod已经被调度至某节点，并且所有容器都已经被kubelet创建完成
- 成功（Succeeded）：pod中的所有容器都已经成功终止并且不会被重启
- 失败（Failed）：所有容器都已经终止，但至少有一个容器终止失败，即容器返回了非0值的退出状态
- 未知（Unknown）：apiserver无法正常获取到pod对象的状态信息，通常由网络通信失败所导致

**pod的创建过程**

1. 用户通过kubectl或其他api客户端提交需要创建的pod信息给apiServer
2. apiServer开始生成pod对象的信息，并将信息存入etcd，然后返回确认信息至客户端
3. apiServer开始反映etcd中的pod对象的变化，其它组件使用watch机制来跟踪检查apiServer上的变动
4. scheduler发现有新的pod对象要创建，开始为Pod分配主机并将结果信息更新至apiServer
5. node节点上的kubelet发现有pod调度过来，尝试调用docker启动容器，并将结果回送至apiServer
6. apiServer将接收到的pod状态信息存入etcd中



**pod的终止过程**

1. 用户向apiServer发送删除pod对象的命令
2. apiServcer中的pod对象信息会随着时间的推移而更新，在宽限期内（默认30s），pod被视为dead
3. 将pod标记为terminating状态
4. kubelet在监控到pod对象转为terminating状态的同时启动pod关闭过程
5. 端点控制器监控到pod对象的关闭行为时将其从所有匹配到此端点的service资源的端点列表中移除
6. 如果当前pod对象定义了preStop钩子处理器，则在其标记为terminating后即会以同步的方式启动执行
7. pod对象中的容器进程收到停止信号
8. 宽限期结束后，若pod中还存在仍在运行的进程，那么pod对象会收到立即终止的信号
9. kubelet请求apiServer将此pod资源的宽限期设置为0从而完成删除操作，此时pod对于用户已不可见



### 2.2 Pod控制器 

Pod是kubernetes的最小管理单元，在kubernetes中，按照pod的创建方式可以将其分为两类：

- 自主式pod：kubernetes直接创建出来的Pod，这种pod删除后就没有了，也不会重建
- 控制器创建的pod：kubernetes通过控制器创建的pod，这种pod删除了之后还会自动重建

**`什么是Pod控制器`**

Pod控制器是管理pod的中间层，使用Pod控制器之后，只需要告诉Pod控制器，想要多少个什么样的Pod就可以了，它会创建出满足条件的Pod并确保每一个Pod资源处于用户期望的目标状态。如果Pod资源在运行中出现故障，它会基于指定策略重新编排Pod。



常见的有Pod控制器有下面这些：

- ReplicationController：比较原始的pod控制器，已经被废弃，由ReplicaSet替代
- ReplicaSet(RS)：保证副本数量一直维持在期望值，并支持pod数量扩缩容，镜像版本升级
- Deployment：通过控制ReplicaSet来控制Pod，并支持滚动升级、回退版本
- Horizontal Pod Autoscaler(HPA)：可以根据集群负载自动水平调整Pod的数量，实现削峰填谷
- DaemonSet：在集群中的指定Node上运行且仅运行一个副本，一般用于守护进程类的任务
- Job：它创建出来的pod只要完成任务就立即退出，不需要重启或重建，用于执行一次性任务
- Cronjob：它创建的Pod负责周期性任务控制，不需要持续后台运行
- StatefulSet：管理有状态应用

#### 2.2.1 ReplicaSet(RS)

ReplicaSet的主要作用是**保证一定数量的pod正常运行**，它会持续监听这些Pod的运行状态，一旦Pod发生故障，就会重启或重建。同时它还支持对pod数量的扩缩容和镜像版本的升降级。 

```perl
# 查看rs
kubectl get rs pc-replicaset -n dev -o wide

# 编辑rs的副本数量，修改spec:replicas: 6即可
kubectl edit rs pc-replicaset -n dev

# 使用scale命令实现扩缩容， 后面--replicas=n直接指定目标数量即可
kubectl scale rs pc-replicaset --replicas=2 -n dev

# 镜像修改 kubectl set image rs rs名称 容器=镜像版本 -n namespace
kubectl set image rs pc-replicaset nginx=nginx:1.17.1  -n dev

执行RS对象的删除
kubectl delete rs pc-replicaset -n dev

如果希望仅仅删除RS对象（保留Pod），可以使用kubectl delete命令时添加--cascade=false选项（不推荐）。
kubectl delete rs pc-replicaset -n dev --cascade=false
```

#### 2.2.2 Deployment

为了更好的解决服务编排的问题，kubernetes在V1.2版本开始，引入了Deployment控制器。值得一提的是，这种控制器并不直接管理pod，而是通过管理ReplicaSet来简介管理Pod，即：Deployment管理ReplicaSet，ReplicaSet管理Pod。所以Deployment比ReplicaSet功能更加强大。

 ![img](04.Kubernetes(02) 快速入门.assets/watermark_04.png)

Deployment主要功能有下面几个：

- 支持ReplicaSet的所有功能
- 支持发布的停止、继续
- 支持滚动升级和回滚版本



deployment支持版本升级过程中的暂停、继续功能以及版本回退等诸多功能，下面具体来看.

kubectl rollout： 版本升级相关功能，支持下面的选项：

- status 显示当前升级状态

- history 显示 升级历史记录

- pause 暂停版本升级过程

- resume 继续已经暂停的版本升级过程

- restart 重启版本升级过程

- undo 回滚到上一级版本（可以使用--to-revision回滚到指定版本）

  ```perl
  # 查看当前升级版本的状态
  kubectl rollout status deploy pc-deployment -n dev
  
  # 查看升级历史记录
  kubectl rollout history deploy pc-deployment -n dev
  
  # 版本回滚
  # 这里直接使用--to-revision=1回滚到了1版本， 如果省略这个选项，就是回退到上个版本，就是2版本
  kubectl rollout undo deployment pc-deployment --to-revision=1 -n dev
  ```

**金丝雀发布**

Deployment控制器支持控制更新过程中的控制，如“暂停(pause)”或“继续(resume)”更新操作。

比如有一批新的Pod资源创建完成后立即暂停更新过程，此时，仅存在一部分新版本的应用，主体部分还是旧的版本。然后，再筛选一小部分的用户请求路由到新版本的Pod应用，继续观察能否稳定地按期望的方式运行。确定没问题之后再继续完成余下的Pod资源滚动更新，否则立即回滚更新操作。这就是所谓的金丝雀发布。

```perl
# 更新deployment的版本，并配置暂停deployment
kubectl set image deploy pc-deployment nginx=nginx:1.17.4 -n dev && kubectl rollout pause deployment pc-deployment  

# 确保更新的pod没问题了，继续更新
kubectl rollout resume deploy pc-deployment -n dev
```

#### 2.2.3 Horizontal Pod Autoscaler

在前面的课程中，我们已经可以实现通过手工执行`kubectl scale`命令实现Pod扩容或缩容，但是这显然不符合Kubernetes的定位目标--自动化、智能化。 Kubernetes期望可以实现通过监测Pod的使用情况，实现pod数量的自动调整，于是就产生了Horizontal Pod Autoscaler（HPA）这种控制器。

HPA可以获取每个Pod利用率，然后和HPA中定义的指标进行对比，同时计算出需要伸缩的具体值，最后实现Pod的数量的调整。其实HPA与之前的Deployment一样，也属于一种Kubernetes资源对象，它通过追踪分析RC控制的所有目标Pod的负载变化情况，来确定是否需要针对性地调整目标Pod的副本数，这是HPA的实现原理。

![img](04.Kubernetes(02) 快速入门.assets/watermark_05.png)

#### 2.2.4 DaemonSet

DaemonSet类型的控制器可以保证在集群中的每一台（或指定）节点上都运行一个副本。一般适用于日志收集、节点监控等场景。也就是说，如果一个Pod提供的功能是节点级别的（每个节点都需要且只需要一个），那么这类Pod就适合使用DaemonSet类型的控制器创建。

 ![img](04.Kubernetes(02) 快速入门.assets/watermark_06.png)



DaemonSet控制器的特点：

- 每当向集群中添加一个节点时，指定的 Pod 副本也将添加到该节点上
- 当节点从集群中移除时，Pod 也就被垃圾回收了

#### 2.2.5 Job

Job，主要用于负责**批量处理(一次要处理指定数量任务)**短暂的**一次性(每个任务仅运行一次就结束)**任务。Job特点如下：

- 当Job创建的pod执行成功结束时，Job将记录成功结束的pod数量
- 当成功结束的pod达到指定的数量时，Job将完成执行

#### 2.2.6 Cronjob

CronJob控制器以Job控制器资源为其管控对象，并借助它管理pod资源对象，Job控制器定义的作业任务在其控制器资源创建之后便会立即执行，但CronJob可以以类似于Linux操作系统的周期性任务作业计划的方式控制其运行**时间点**及**重复运行**的方式。也就是说，**CronJob可以在特定的时间点(反复的)去运行job任务**。

 ![img](04.Kubernetes(02) 快速入门.assets/watermark_07.png)



#### 2.2.7 实例

常用命令

```perl
# 查看Pod基本信息
kubectl get pods -n dev
# 查看Pod的详细信息
kubectl describe pod nginx -n dev
# 获取podIP
kubectl get pods -n dev -o wide
# 访问POD
curl http://10.244.1.23:80
# 删除指定Pod
kubectl delete pod nginx -n dev
```



kubernetes在集群启动之后，集群中的各个组件也都是以Pod方式运行的。可以通过下面命令查看：

```perl
[root@master ~]# kubectl get pod -n kube-system
NAMESPACE   NAME                            READY  STATUS   RESTARTS  AGE
kube-system  coredns-6955765f44-68g6v        1/1   Running  0        2d1h
kube-system  coredns-6955765f44-cs5r8        1/1   Running  0        2d1h
kube-system  etcd-master                     1/1   Running  0        2d1h
kube-system  kube-apiserver-master           1/1   Running  0        2d1h
kube-system  kube-controller-manager-master  1/1   Running  0        2d1h
kube-system  kube-flannel-ds-amd64-47r25     1/1   Running  0        2d1h
kube-system  kube-flannel-ds-amd64-ls5lh     1/1   Running  0        2d1h
kube-system  kube-proxy-685tk                1/1   Running  0        2d1h
kube-system  kube-proxy-87spt                1/1   Running  0        2d1h
kube-system  kube-scheduler-master           1/1   Running  0        2d1h
```



Pod相关命令：

* **创建并运行**
  kubernetes没有提供单独运行Pod的命令，都是通过Pod控制器来实现的

  ```perl
  # 命令格式： kubectl run (pod控制器名称) [参数] 
  # --image  指定Pod的镜像
  # --port   指定端口
  # --namespace  指定namespace
  [root@master ~]# kubectl run nginx --image=nginx:1.20.1 --port=80 --namespace dev 
  deployment.apps/nginx created
  ```

* **查看pod信息**

  ```perl
  # 查看Pod基本信息
  [root@master ~]# kubectl get pods -n dev
  NAME                     READY   STATUS    RESTARTS   AGE
  nginx-5ff7956ff6-fg2db   1/1     Running   0          43s
  
  # 查看Pod的详细信息
  [root@master ~]# kubectl describe pod nginx-5ff7956ff6-fg2db -n dev
  Name:         nginx-5ff7956ff6-fg2db
  Namespace:    dev
  Priority:     0
  Node:         node1/192.168.109.101
  Start Time:   Wed, 08 Apr 2020 09:29:24 +0800
  Labels:       pod-template-hash=5ff7956ff6
                run=nginx
  Annotations:  <none>
  Status:       Running
  IP:           10.244.1.23
  IPs:
    IP:           10.244.1.23
  Controlled By:  ReplicaSet/nginx-5ff7956ff6
  Containers:
    nginx:
      Container ID:   docker://4c62b8c0648d2512380f4ffa5da2c99d16e05634979973449c98e9b829f6253c
      Image:          nginx:1.20.1
      Image ID:       docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7
      Port:           80/TCP
      Host Port:      0/TCP
      State:          Running
        Started:      Wed, 08 Apr 2020 09:30:01 +0800
      Ready:          True
      Restart Count:  0
      Environment:    <none>
      Mounts:
        /var/run/secrets/kubernetes.io/serviceaccount from default-token-hwvvw (ro)
  Conditions:
    Type              Status
    Initialized       True
    Ready             True
    ContainersReady   True
    PodScheduled      True
  Volumes:
    default-token-hwvvw:
      Type:        Secret (a volume populated by a Secret)
      SecretName:  default-token-hwvvw
      Optional:    false
  QoS Class:       BestEffort
  Node-Selectors:  <none>
  Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                   node.kubernetes.io/unreachable:NoExecute for 300s
  Events:
    Type    Reason     Age        From               Message
    ----    ------     ----       ----               -------
    Normal  Scheduled  <unknown>  default-scheduler  Successfully assigned dev/nginx-5ff7956ff6-fg2db to node1
    Normal  Pulling    4m11s      kubelet, node1     Pulling image "nginx:1.20.1"
    Normal  Pulled     3m36s      kubelet, node1     Successfully pulled image "nginx:1.20.1"
    Normal  Created    3m36s      kubelet, node1     Created container nginx
    Normal  Started    3m36s      kubelet, node1     Started container nginx
  ```

* **访问Pod**

  ```perl
  # 获取podIP
  [root@master ~]# kubectl get pods -n dev -o wide
  NAME                     READY   STATUS    RESTARTS   AGE    IP             NODE    ... 
  nginx-5ff7956ff6-fg2db   1/1     Running   0          190s   10.244.1.23   node1   ...
  
  #访问POD
  [root@master ~]# curl http://10.244.1.23:80
  <!DOCTYPE html>
  <html>
  <head>
      <title>Welcome to nginx!</title>
  </head>
  <body>
      <p><em>Thank you for using nginx.</em></p>
  </body>
  </html>
  ```

* **删除指定Pod**

  ```perl
  # 删除指定Pod
  [root@master ~]# kubectl delete pod nginx-5ff7956ff6-fg2db -n dev
  pod "nginx-5ff7956ff6-fg2db" deleted
  
  # 此时，显示删除Pod成功，但是再查询，发现又新产生了一个 
  [root@master ~]# kubectl get pods -n dev
  NAME                     READY   STATUS    RESTARTS   AGE
  nginx-5ff7956ff6-jj4ng   1/1     Running   0          21s
  
  # 这是因为当前Pod是由Pod控制器创建的，控制器会监控Pod状况，一旦发现Pod死亡，会立即重建
  # 此时要想删除Pod，必须删除Pod控制器
  
  # 先来查询一下当前namespace下的Pod控制器
  [root@master ~]# kubectl get deploy -n  dev
  NAME    READY   UP-TO-DATE   AVAILABLE   AGE
  nginx   1/1     1            1           9m7s
  
  # 接下来，删除此PodPod控制器
  [root@master ~]# kubectl delete deploy nginx -n dev
  deployment.apps "nginx" deleted
  
  # 稍等片刻，再查询Pod，发现Pod被删除了
  [root@master ~]# kubectl get pods -n dev
  No resources found in dev namespace.
  ```

* **配置操作**
  创建一个pod-nginx.yaml，内容如下：

  ```perl
  apiVersion: v1
  kind: Pod
  metadata:
    name: nginx
    namespace: dev
  spec:
    containers:
    - image: nginx:1.20.1
      name: pod
      ports:
      - name: nginx-port
        containerPort: 80
        protocol: TCP
  ```

然后就可以执行对应的创建和删除命令了：

- 创建：kubectl  create  -f  pod-nginx.yaml

- 删除：kubectl  delete  -f  pod-nginx.yaml



## 3. Label

Label是kubernetes系统中的一个重要概念。它的作用就是在资源上添加标识，用来对它们进行区分和选择。

 Label的特点：

- 一个Label会以key/value键值对的形式附加到各种对象上，如Node、Pod、Service等等

- 一个资源对象可以定义任意数量的Label ，同一个Label也可以被添加到任意数量的资源对象上去

- Label通常在资源对象定义时确定，当然也可以在对象创建后动态添加或者删除

  

可以通过Label实现资源的多维度分组，以便灵活、方便地进行资源分配、调度、配置、部署等管理工作。

```perl
一些常用的Label 示例如下：
版本标签："version":"release", "version":"stable"......
环境标签："environment":"dev"，"environment":"test"，"environment":"pro"
架构标签："tier":"frontend"，"tier":"backend"
```

 

标签定义完毕之后，还要考虑到标签的选择，这就要使用到Label Selector，即：

- Label用于给某个资源对象定义标识

- Label Selector用于查询和筛选拥有某些标签的资源对象

  

当前有两种Label Selector：

- 基于等式的Label Selector
  - name = slave：选择所有包含Label中key="name"且value="slave"的对象
  - env != production：选择所有包括Label中的key="env"且value不等于"production"的对象
- 基于集合的Label Selector
  - name in (master, slave)：选择所有包含Label中的key="name"且value="master"或"slave"的对象
  - name not in (frontend)：选择所有包含Label中的key="name"且value不等于"frontend"的对象
  - 

标签的选择条件可以使用多个，此时将多个Label Selector进行组合，使用逗号","进行分隔即可。例如：

```perl
name=slave，env!=production
name not in (frontend)，env!=production
```

Label相关命令：

```perl
1 为pod资源打标签：kubectl label pod nginx-pod version=1.0 -n dev
2 为pod资源更新标签：kubectl label pod nginx-pod version=2.0 -n dev --overwrite
3 查看标签：kubectl get pod nginx-pod -n dev --show-labels
4 筛选标签：
　　kubectl get pod -n dev -l version=2.0 --show-labels
　　kubectl get pod -n dev -l version!=2.0 --show-labels
5 删除标签：kubectl label pod nginx-pod version- -n dev
```

**命令方式**

```ruby
# 为pod资源打标签
[root@master ~]# kubectl label pod nginx-pod version=1.0 -n dev
pod/nginx-pod labeled

# 为pod资源更新标签
[root@master ~]# kubectl label pod nginx-pod version=2.0 -n dev --overwrite
pod/nginx-pod labeled

# 查看标签
[root@master ~]# kubectl get pod nginx-pod  -n dev --show-labels
NAME        READY   STATUS    RESTARTS   AGE   LABELS
nginx-pod   1/1     Running   0          10m   version=2.0

# 筛选标签
[root@master ~]# kubectl get pod -n dev -l version=2.0  --show-labels
NAME        READY   STATUS    RESTARTS   AGE   LABELS
nginx-pod   1/1     Running   0          17m   version=2.0
[root@master ~]# kubectl get pod -n dev -l version!=2.0 --show-labels
No resources found in dev namespace.

#删除标签
[root@master ~]# kubectl label pod nginx-pod version- -n dev
pod/nginx-pod labeled
```

**配置方式 Label.yaml**

```perl
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  namespace: dev
  labels:
    version: "3.0" 
    env: "test"
spec:
  containers:
  - image: nginx:1.20.1
    name: pod
    ports: #指定放行的端口
    - name: nginx-port
      containerPort: 80
      protocol: TCP
```

然后就可以执行对应的更新命令了：kubectl  apply  -f  pod-nginx.yaml



## 4. Deployment

在kubernetes中，Pod是最小的控制单元，但是kubernetes很少直接控制Pod，一般都是通过Pod控制器来完成的。Pod控制器用于pod的管理，确保pod资源符合预期的状态，当pod的资源出现故障时，会尝试进行重启或重建pod。

在kubernetes中Pod控制器的种类有很多，本文只介绍一种：Deployment。

![image-20220522105706721](04.Kubernetes(02) 快速入门.assets/image-20220522105706721.png)



* **命令操作**

  ```perl
  # 命令格式: kubectl run deployment名称  [参数] 
  # --image  指定pod的镜像
  # --port   指定端口
  # --replicas  指定创建pod数量
  # --namespace  指定namespace
  [root@master ~]# kubectl run nginx --image=nginx:1.20.1 --port=80 --replicas=3 -n dev
  deployment.apps/nginx created
  ```

* **查看创建的Pod**

  ```perl
  # 查看创建的Pod
  [root@master ~]# kubectl get pods -n dev
  NAME                     READY   STATUS    RESTARTS   AGE
  nginx-5ff7956ff6-6k8cb   1/1     Running   0          19s
  nginx-5ff7956ff6-jxfjt   1/1     Running   0          19s
  nginx-5ff7956ff6-v6jqw   1/1     Running   0          19s
  ```

* **查看deployment的信息**

  ```perl
  # 查看deployment的信息
  [root@master ~]# kubectl get deploy -n dev
  NAME    READY   UP-TO-DATE   AVAILABLE   AGE
  nginx   3/3     3            3           2m42s
  
  # UP-TO-DATE：成功升级的副本数量
  # AVAILABLE：可用副本的数量
  [root@master ~]# kubectl get deploy -n dev -o wide
  NAME    READY UP-TO-DATE  AVAILABLE   AGE     CONTAINERS   IMAGES              SELECTOR
  nginx   3/3     3         3           2m51s   nginx        nginx:1.20.1        run=nginx
  ```

* **查看deployment的详细信息**

  ```perl
  # 查看deployment的详细信息
  [root@master ~]# kubectl describe deploy nginx -n dev
  Name:                   nginx
  Namespace:              dev
  CreationTimestamp:      Wed, 08 Apr 2020 11:14:14 +0800
  Labels:                 run=nginx
  Annotations:            deployment.kubernetes.io/revision: 1
  Selector:               run=nginx
  Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
  StrategyType:           RollingUpdate
  MinReadySeconds:        0
  RollingUpdateStrategy:  25% max unavailable, 25% max surge
  Pod Template:
    Labels:  run=nginx
    Containers:
     nginx:
      Image:        nginx:1.20.1
      Port:         80/TCP
      Host Port:    0/TCP
      Environment:  <none>
      Mounts:       <none>
    Volumes:        <none>
  Conditions:
    Type           Status  Reason
    ----           ------  ------
    Available      True    MinimumReplicasAvailable
    Progressing    True    NewReplicaSetAvailable
  OldReplicaSets:  <none>
  NewReplicaSet:   nginx-5ff7956ff6 (3/3 replicas created)
  Events:
    Type    Reason             Age    From                   Message
    ----    ------             ----   ----                   -------
    Normal  ScalingReplicaSet  5m43s  deployment-controller  Scaled up replicaset nginx-5ff7956ff6 to 3
  ```

* **删除**

  ```perl
  # 删除 
  [root@master ~]# kubectl delete deploy nginx -n dev
  deployment.apps "nginx" deleted
  ```

* **配置操作**
  创建一个deploy-nginx.yaml，内容如下：

  ```perl
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: nginx
    namespace: dev
  spec:
    replicas: 3
    selector:
      matchLabels:
        run: nginx
    template:
      metadata:
        labels:
          run: nginx
      spec:
        containers:
        - image: nginx:1.20.1
          name: nginx
          ports:
          - containerPort: 80
            protocol: TCP
  ```

然后就可以执行对应的创建和删除命令了：

- 创建：kubectl  create  -f  deploy-nginx.yaml

- 删除：kubectl  delete  -f  deploy-nginx.yaml

  

## 5. Service

在kubernetes中，pod是应用程序的载体，我们可以通过pod的ip来访问应用程序，但是pod的ip地址不是固定的，这也就意味着不方便直接采用pod的ip对服务进行访问。

为了解决这个问题，kubernetes提供了Service资源，Service会对提供同一个服务的多个pod进行聚合，并且提供一个统一的入口地址。通过访问Service的入口地址就能访问到后面的pod服务。



Service在很多情况下只是一个概念，真正起作用的其实是kube-proxy服务进程，每个Node节点上都运行着一个kube-proxy服务进程。当创建Service的时候会通过api-server向etcd写入创建的service的信息，而kube-proxy会基于监听的机制发现这种Service的变动，然后**它会将最新的Service信息转换成对应的访问规则**。

![img](04.Kubernetes(02) 快速入门.assets/watermark_08.png)



**kube-proxy目前支持三种工作模式:**

**1. userspace 模式**

userspace模式下，kube-proxy会为每一个Service创建一个监听端口，发向Cluster IP的请求被Iptables规则重定向到kube-proxy监听的端口上，kube-proxy根据LB算法选择一个提供服务的Pod并和其建立链接，以将请求转发到Pod上。  该模式下，kube-proxy充当了一个四层负责均衡器的角色。由于kube-proxy运行在userspace中，在进行转发处理时会增加内核和用户空间之间的数据拷贝，虽然比较稳定，但是效率比较低。 

![img](04.Kubernetes(02) 快速入门.assets/watermark_09.png)

**2. iptables 模式**

iptables模式下，kube-proxy为service后端的每个Pod创建对应的iptables规则，直接将发向Cluster IP的请求重定向到一个Pod IP。  该模式下kube-proxy不承担四层负责均衡器的角色，只负责创建iptables规则。该模式的优点是较userspace模式效率更高，但不能提供灵活的LB策略，当后端Pod不可用时也无法进行重试。

![img](04.Kubernetes(02) 快速入门.assets/watermark_10.png)

**3. ipvs 模式**

ipvs模式和iptables类似，kube-proxy监控Pod的变化并创建相应的ipvs规则。ipvs相对iptables转发效率更高。除此以外，ipvs支持更多的LB算法。

![img](04.Kubernetes(02) 快速入门.assets/watermark_11.png)

 Service常用类型

- ClusterIP：默认值，它是Kubernetes系统自动分配的虚拟IP，只能在集群内部访问
- NodePort：将Service通过指定的Node上的端口暴露给外部，通过此方法，就可以在集群外部访问服务
- LoadBalancer：使用外接负载均衡器完成到服务的负载分发，注意此模式需要外部云环境支持
- ExternalName： 把集群外部的服务引入集群内部，直接使用

### 5.1 ClusterIP类型的Service 

**Endpoint**

Endpoint是kubernetes中的一个资源对象，存储在etcd中，用来记录一个service对应的所有pod的访问地址，它是根据service配置文件中selector描述产生的。

一个Service由一组Pod组成，这些Pod通过Endpoints暴露出来，**Endpoints是实现实际服务的端点集合**。换句话说，service和pod之间的联系是通过endpoints实现的。

![img](04.Kubernetes(02) 快速入门.assets/watermark_12.png)



**负载分发策略**

对Service的访问被分发到了后端的Pod上去，目前kubernetes提供了两种负载分发策略：

- 如果不定义，默认使用kube-proxy的策略，比如随机、轮询

- 基于客户端地址的会话保持模式，即来自同一个客户端发起的所有请求都会转发到固定的一个Pod上

  此模式可以使在spec中添加`sessionAffinity:ClientIP`选项

```
# 查看service
kubectl get svc -n dev -o wide

# 查看service的详细信息
# 在这里有一个Endpoints列表，里面就是当前service可以负载到的服务入口
kubectl describe svc service-clusterip -n dev

# 查看ipvs的映射规则【rr 轮询】
ipvsadm -Ln

# 查看域名的解析情况
kubectl exec -it pc-deployment-66cb59b984-8p84h -n dev /bin/sh
```

### 5.2 HeadLiness类型的Service 

在某些场景中，开发人员可能不想使用Service提供的负载均衡功能，而希望自己来控制负载均衡策略，针对这种情况，kubernetes提供了HeadLiness Service，这类Service不会分配Cluster IP，如果想要访问service，只能通过service的域名进行查询。

### 5.3 NodePort类型的Service

在之前的样例中，创建的Service的ip地址只有集群内部才可以访问，如果希望将Service暴露给集群外部使用，那么就要使用到另外一种类型的Service，称为NodePort类型。NodePort的工作原理其实就是**将service的端口映射到Node的一个端口上**，然后就可以通过`NodeIp:NodePort`来访问service了。

![img](04.Kubernetes(02) 快速入门.assets/watermark_14.png)

###  5.4 LoadBalancer类型的Service

LoadBalancer和NodePort很相似，目的都是向外部暴露一个端口，区别在于LoadBalancer会在集群的外部再来做一个负载均衡设备，而这个设备需要外部环境支持的，外部服务发送到这个设备上的请求，会被设备负载之后转发到集群中。

![img](04.Kubernetes(02) 快速入门.assets/watermark_13.png)

###  5.5 ExternalName类型的Service

ExternalName类型的Service用于引入集群外部的服务，它通过`externalName`属性指定外部一个服务的地址，然后在集群内部访问此service就可以访问到外部的服务了。

![img](04.Kubernetes(02) 快速入门.assets/watermark_15.png)

### 5.6 实例

前面已经能够利用Deployment来创建一组Pod来提供具有高可用性的服务。

虽然每个Pod都会分配一个单独的Pod IP，然而却存在如下两问题：

- Pod IP 会随着Pod的重建产生变化。
- Pod IP 仅仅是集群内可见的虚拟IP，外部无法访问。

这样对于访问这个服务带来了难度。因此，kubernetes设计了Service来解决这个问题。

Service可以看作是一组同类Pod**对外的访问接口**。借助Service，应用可以方便地实现服务发现和负载均衡。

![image-20220523184245413](04.Kubernetes(02) 快速入门.assets/image-20220523184245413.png)

**操作一：创建集群内部可访问的Service**

```xml
# 暴露Service
[root@master ~]# kubectl expose deploy nginx --name=svc-nginx1 --type=ClusterIP --port=80 --target-port=80 -n dev
service/svc-nginx1 exposed

# 查看service
[root@master ~]# kubectl get svc svc-nginx -n dev -o wide
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE     SELECTOR
svc-nginx1   ClusterIP   10.109.179.231   <none>        80/TCP    3m51s   run=nginx

# 这里产生了一个CLUSTER-IP，这就是service的IP，在Service的生命周期中，这个地址是不会变动的
# 可以通过这个IP访问当前service对应的POD
[root@master ~]# curl 10.109.179.231:80
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
</head>
<body>
<h1>Welcome to nginx!</h1>
.......
</body>
</html>
```

**操作二：创建集群外部也可访问的Service**

```csharp
# 上面创建的Service的type类型为ClusterIP，这个ip地址只用集群内部可访问
# 如果需要创建外部也可以访问的Service，需要修改type为NodePort
[root@master ~]# kubectl expose deploy nginx --name=svc-nginx2 --type=NodePort --port=80 --target-port=80 -n dev
service/svc-nginx2 exposed

# 此时查看，会发现出现了NodePort类型的Service，而且有一对Port（80:31928/TC）
[root@master ~]# kubectl get svc  svc-nginx-1  -n dev -o wide
NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE    SELECTOR
svc-nginx2    NodePort    10.100.94.0      <none>        80:31928/TCP   9s     run=nginx

# 接下来就可以通过集群外的主机访问 节点IP:31928访问服务了
# 例如在的电脑主机上通过浏览器访问下面的地址
http://192.168.109.100:31928/
```

**删除Service**

```csharp
[root@master ~]# kubectl delete svc svc-nginx-1 -n dev                                   
service "svc-nginx-1" deleted
```

**配置方式**
 创建一个svc-nginx.yaml，内容如下：

```css
apiVersion: v1
kind: Service
metadata:
  name: svc-nginx
  namespace: dev
spec:
  clusterIP: 10.109.179.231
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    run: nginx
  type: ClusterIP
```

然后就可以执行对应的创建和删除命令了：

- 创建：kubectl  create  -f  svc-nginx.yaml
- 删除：kubectl  delete  -f  svc-nginx.yaml



## 6 Volume 

为了持久化保存容器的数据，kubernetes引入了Volume的概念。

Volume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命容器不与Pod中单个容器的生命周期相关，当容器终止或者重启时，Volume中的数据也不会丢失。

kubernetes的Volume支持多种类型，比较常见的有下面几个：

- 简单存储：EmptyDir、HostPath、NFS
- 高级存储：PV、PVC
- 配置存储：ConfigMap、Secret 

###  6.1 基本存储

* EmptyDir

  EmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录。

  EmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时， EmptyDir中的数据也会被永久删除。 EmptyDir用途如下：

  - 临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留

  - 一个容器需要从另一个容器中获取数据的目录（多容器共享目录）


* HostPath

  EmptyDir中数据不会被持久化，它会随着Pod的结束而销毁，如果想简单的将数据持久化到主机中，可以选择HostPath。

  HostPath就是将Node主机中一个实际目录挂在到Pod中，以供容器使用，这样的设计就可以保证Pod销毁了，但是数据依据可以存在于Node主机上。

* NFS

  HostPath可以解决数据持久化的问题，但是一旦Node节点故障了，Pod如果转移到了别的节点，又会出现问题了，此时需要准备单独的网络存储系统，比较常用的用NFS、CIFS。

  NFS是一个网络文件存储系统，可以搭建一台NFS服务器，然后将Pod中的存储直接连接到NFS系统上，这样的话，无论Pod在节点上怎么转移，只要Node跟NFS的对接没问题，数据就可以成功访问。

###  6.2 高级存储

PV（Persistent Volume）是持久化卷的意思，是对底层的共享存储的一种抽象。一般情况下PV由kubernetes管理员进行创建和配置，它与底层具体的共享存储技术有关，并通过插件完成与共享存储的对接。

PVC（Persistent Volume Claim）是持久卷声明的意思，是用户对于存储需求的一种声明。换句话说，PVC其实就是用户向kubernetes系统发出的一种资源需求申请。



<img src="04.Kubernetes(02) 快速入门.assets/watermark_16.png" alt="img" style="zoom:80%;" />

使用了PV和PVC之后，工作可以得到进一步的细分：

- 存储：存储工程师维护
- PV： kubernetes管理员维护
- PVC：kubernetes用户维护

PVC和PV是一一对应的，PV和PVC之间的相互作用遵循以下生命周期：

- **资源供应**：管理员手动创建底层存储和PV

- **资源绑定**：用户创建PVC，kubernetes负责根据PVC的声明去寻找PV，并绑定

  在用户定义好PVC之后，系统将根据PVC对存储资源的请求在已存在的PV中选择一个满足条件的

  - 一旦找到，就将该PV与用户定义的PVC进行绑定，用户的应用就可以使用这个PVC了
  - 如果找不到，PVC则会无限期处于Pending状态，直到等到系统管理员创建了一个符合其要求的PV

  PV一旦绑定到某个PVC上，就会被这个PVC独占，不能再与其他PVC进行绑定了

- **资源使用**：用户可在pod中像volume一样使用pvc

  Pod使用Volume的定义，将PVC挂载到容器内的某个路径进行使用。

- **资源释放**：用户删除pvc来释放pv

  当存储资源使用完毕后，用户可以删除PVC，与该PVC绑定的PV将会被标记为“已释放”，但还不能立刻与其他PVC进行绑定。通过之前PVC写入的数据可能还被留在存储设备上，只有在清除之后该PV才能再次使用。

- **资源回收**：kubernetes根据pv设置的回收策略进行资源的回收

  对于PV，管理员可以设定回收策略，用于设置与之绑定的PVC释放资源之后如何处理遗留数据的问题。只有PV的存储空间完成回收，才能供新的PVC绑定和使用

 ![img](04.Kubernetes(02) 快速入门.assets/watermark_17.png)



**1. PV**

PV 的关键配置参数说明：

- **存储类型**

  底层实际存储的类型，kubernetes支持多种存储类型，每种存储类型的配置都有所差异

- **存储能力（capacity）**

目前只支持存储空间的设置( storage=1Gi )，不过未来可能会加入IOPS、吞吐量等指标的配置

- **访问模式（accessModes）**

  用于描述用户应用对存储资源的访问权限，访问权限包括下面几种方式：

  - ReadWriteOnce（RWO）：读写权限，但是只能被单个节点挂载
  - ReadOnlyMany（ROX）： 只读权限，可以被多个节点挂载
  - ReadWriteMany（RWX）：读写权限，可以被多个节点挂载

  `需要注意的是，底层不同的存储类型可能支持的访问模式不同`

- **回收策略（persistentVolumeReclaimPolicy）**

  当PV不再被使用了之后，对其的处理方式。目前支持三种策略：

  - Retain （保留） 保留数据，需要管理员手工清理数据
  - Recycle（回收） 清除 PV 中的数据，效果相当于执行 rm -rf /thevolume/*
  - Delete （删除） 与 PV 相连的后端存储完成 volume 的删除操作，当然这常见于云服务商的存储服务

  `需要注意的是，底层不同的存储类型可能支持的回收策略不同`

- **存储类别**

  PV可以通过storageClassName参数指定一个存储类别

  - 具有特定类别的PV只能与请求了该类别的PVC进行绑定
  - 未设定类别的PV则只能与不请求任何类别的PVC进行绑定

- **状态（status）**

  一个 PV 的生命周期中，可能会处于4中不同的阶段：

  - Available（可用）： 表示可用状态，还未被任何 PVC 绑定
  - Bound（已绑定）： 表示 PV 已经被 PVC 绑定
  - Released（已释放）： 表示 PVC 被删除，但是资源还未被集群重新声明
  - Failed（失败）： 表示该 PV 的自动回收失败



**2. PVC**

PVC是资源的申请，用来声明对存储空间、访问模式、存储类别需求信息。

PVC 的关键配置参数说明：

- **访问模式（accessModes）**

用于描述用户应用对存储资源的访问权限

- **选择条件（selector）**

  通过Label Selector的设置，可使PVC对于系统中己存在的PV进行筛选

- **存储类别（storageClassName）**

  PVC在定义时可以设定需要的后端存储的类别，只有设置了该class的pv才能被系统选出

- **资源请求（Resources ）**

  描述对存储资源的请求

###  6.3 配置存储

* ConfigMap

  ConfigMap是一种比较特殊的存储卷，它的主要作用是用来存储配置信息的。

* Secret

  在kubernetes中，还存在一种和ConfigMap非常类似的对象，称为Secret对象。它主要用于存储敏感信息，例如密码、秘钥、证书等等。

  > \1) 首先使用base64对数据进行编码
  >
  > [root@k8s-master01 ~]# echo -n 'admin' | base64 #准备username
  > YWRtaW4=
  > [root@k8s-master01 ~]# echo -n '123456' | base64 #准备password
  > MTIzNDU2
  >
  > \2) 接下来编写secret.yaml，并创建Secret
  >
  > apiVersion: v1
  > kind: Secret
  > metadata:
  > name: secret
  > namespace: dev
  > type: Opaque
  > data:
  > username: YWRtaW4=
  > password: MTIzNDU2



## 7. 小结

至此，介绍了Namespace、Pod、Deployment、Service资源的基本操作，有了这些操作，就可以在kubernetes集群中实现一个服务的简单部署和访问了，但是如果想要更好的使用kubernetes，就需要深入学习这几种资源的细节和原理。
